"""
ç²¾æ­¦è‹±é›„æ­Œè¯è§†é¢‘ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆï¼ˆé‡æ„ä¿®å¤ç»ˆç‰ˆï¼‰
æ”¯æŒèƒŒæ™¯å›¾ç‰‡ã€å‘å…‰æ•ˆæœå’ŒåŒè¯­æ¨¡å¼
"""

import os
import time
from typing import List, Optional
from moviepy import AudioFileClip, ImageClip, CompositeVideoClip, ColorClip
from PIL import Image, ImageFilter, ImageEnhance
import numpy as np
import traceback
from pathlib import Path
from lrc_mv_config import load_lrc_mv_config

# å¯¼å…¥LyricTimelineç›¸å…³ç±»
from lyric_timeline import LyricTimeline, LyricDisplayMode
from layout_engine import LayoutEngine, VerticalStackStrategy
from lyric_clip import LyricClip, create_lyric_clip

DEFAULT_WIDTH = 720
DEFAULT_HEIGHT = 1280
DEFAULT_FPS = 24

class EnhancedJingwuGenerator:
    """å¢å¼ºç‰ˆç²¾æ­¦è‹±é›„æ­Œè¯è§†é¢‘ç”Ÿæˆå™¨ï¼ˆé‡æ„ä¿®å¤ç»ˆç‰ˆï¼‰"""

    def __init__(self, width: int = DEFAULT_WIDTH, height: int = DEFAULT_HEIGHT, fps: int = DEFAULT_FPS):
        self.width = width
        self.height = height
        self.fps = fps
        self.default_font_size = 80
        self.default_font_color = 'white'
        self.highlight_color = '#FFD700'  # é‡‘è‰²
        self.shadow_color = (0, 0, 0, 200)

        self.theme_colors = {
            'gold': '#FFD700',
            'red': '#DC143C',
            'dark_red': '#8B0000',
            'black': '#000000',
            'white': '#FFFFFF',
            'silver': '#C0C0C0'
        }





    def load_background_image(self, bg_path: str) -> Optional[np.ndarray]:
        """åŠ è½½å¹¶å¤„ç†èƒŒæ™¯å›¾ç‰‡"""
        try:
            img = Image.open(bg_path)
            # PILç‰ˆæœ¬å…¼å®¹æ€§å¤„ç†
            try:
                img = img.resize((self.width, self.height), Image.Resampling.LANCZOS)
            except AttributeError:
                # è¾ƒæ—§çš„PILç‰ˆæœ¬å›é€€
                img = img.resize((self.width, self.height))

            enhancer = ImageEnhance.Brightness(img)
            img = enhancer.enhance(0.4)
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(0.6)
            img = img.filter(ImageFilter.GaussianBlur(radius=1))
            return np.array(img)
        except Exception as e:
            print(f"âš ï¸  èƒŒæ™¯å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
            return None

    def create_gradient_background(self, color1: tuple, color2: tuple) -> np.ndarray:
        """åˆ›å»ºæ¸å˜èƒŒæ™¯"""
        gradient = np.zeros((self.height, self.width, 3), dtype=np.uint8)
        for y in range(self.height):
            ratio = y / self.height
            r = int(color1[0] * (1 - ratio) + color2[0] * ratio)
            g = int(color1[1] * (1 - ratio) + color2[1] * ratio)
            b = int(color1[2] * (1 - ratio) + color2[2] * ratio)
            gradient[y, :] = [r, g, b]
        return gradient

    # create_enhanced_text_imageæ–¹æ³•å·²ç§»é™¤
    # æ–°çš„LyricClipæ¶æ„ä½¿ç”¨ç»Ÿä¸€çš„frame_functionæ¸²æŸ“ç®¡é“
    # æ–‡æœ¬æ¸²æŸ“ç°åœ¨é€šè¿‡lyric_clip.pyä¸­çš„LyricClip._render_lyric_on_frame()å¤„ç†

    # create_lyric_clip_with_animationæ–¹æ³•å·²ç§»é™¤
    # æ–°çš„LyricClipæ¶æ„ä¸å†éœ€è¦ä¸ºæ¯å¥æ­Œè¯åˆ›å»ºå•ç‹¬çš„ImageClip
    # æ‰€æœ‰æ­Œè¯æ¸²æŸ“ç°åœ¨é€šè¿‡LyricClipçš„ç»Ÿä¸€frame_functionå¤„ç†

    def create_lyric_clip(self, timelines: List[LyricTimeline],
                         duration: float) -> LyricClip:
        """åˆ›å»ºLyricClipï¼ˆæ–°æ–¹å¼ï¼‰

        Args:
            timelines: æ­Œè¯æ—¶é—´è½´åˆ—è¡¨
            duration: è§†é¢‘æ—¶é•¿

        Returns:
            LyricClipå®ä¾‹
        """
        # åˆ›å»ºå¸ƒå±€å¼•æ“
        layout_engine = LayoutEngine(VerticalStackStrategy(spacing=30))

        # æ·»åŠ æ‰€æœ‰æ—¶é—´è½´
        for timeline in timelines:
            layout_engine.add_element(timeline)

        # åˆ›å»ºLyricClip
        return create_lyric_clip(
            timelines=timelines,
            layout_engine=layout_engine,
            size=(self.width, self.height),
            duration=duration,
            fps=self.fps
        )

    def _generate_video_with_lyric_clip(self, lyric_clip: LyricClip,
                                       background_clip, audio_clip,
                                       output_path: str, draft_mode: bool = False):
        """ä½¿ç”¨LyricClipçš„è§†é¢‘ç”Ÿæˆæ–¹æ³•

        Args:
            lyric_clip: LyricClipå®ä¾‹
            background_clip: èƒŒæ™¯ç‰‡æ®µ
            audio_clip: éŸ³é¢‘ç‰‡æ®µ
            output_path: è¾“å‡ºè·¯å¾„
            draft_mode: è‰ç¨¿æ¨¡å¼
        """
        print("ä½¿ç”¨LyricClipåˆæˆè§†é¢‘...")

        # åˆæˆè§†é¢‘ï¼ˆèƒŒæ™¯ + LyricClipï¼‰
        all_clips = [background_clip, lyric_clip]

        # ä½¿ç”¨ç°æœ‰çš„åˆæˆå’Œå¯¼å‡ºé€»è¾‘
        self._finalize_and_export_video(
            all_clips=all_clips,
            audio_clip=audio_clip,
            output_path=output_path,
            temp_audio_file_suffix="lyric_clip",
            draft_mode=draft_mode
        )

    def _apply_layout_to_timeline(self, timeline: 'LyricTimeline', target_rect):
        """å°†å¸ƒå±€ç»“æœåº”ç”¨åˆ°æ—¶é—´è½´

        æ ¹æ®ç›®æ ‡çŸ©å½¢è°ƒæ•´æ—¶é—´è½´çš„æ˜¾ç¤ºç­–ç•¥å‚æ•°
        """
        from lyric_timeline import LyricDisplayMode

        if timeline.display_mode == LyricDisplayMode.SIMPLE_FADE:
            # å¯¹äºç®€å•æ¨¡å¼ï¼Œè°ƒæ•´Yä½ç½®
            timeline.set_display_mode(
                LyricDisplayMode.SIMPLE_FADE,
                y_position=target_rect.y + target_rect.height // 2,
                is_highlighted=getattr(timeline._strategy, 'is_highlighted', False)
            )
        elif timeline.display_mode == LyricDisplayMode.ENHANCED_PREVIEW:
            # å¯¹äºå¢å¼ºé¢„è§ˆæ¨¡å¼ï¼Œè°ƒæ•´åç§»é‡
            center_y = target_rect.y + target_rect.height // 2
            timeline.set_display_mode(
                LyricDisplayMode.ENHANCED_PREVIEW,
                current_y_offset=center_y - self.height // 2 - 50,
                preview_y_offset=center_y - self.height // 2 + 80
            )

        print(f"  å·²åº”ç”¨å¸ƒå±€åˆ° {timeline.element_id}: Y={target_rect.y}, H={target_rect.height}")

    def _validate_clips_duration(self, clips: List[ImageClip], max_duration: float) -> List[ImageClip]:
        """éªŒè¯å¹¶ä¿®æ­£ç‰‡æ®µæ—¶é•¿ï¼Œç¡®ä¿æ‰€æœ‰ç‰‡æ®µéƒ½åœ¨æ—¶é•¿é™åˆ¶å†…

        Args:
            clips: å¾…éªŒè¯çš„ç‰‡æ®µåˆ—è¡¨
            max_duration: æœ€å¤§æ—¶é•¿é™åˆ¶

        Returns:
            éªŒè¯å¹¶ä¿®æ­£åçš„ç‰‡æ®µåˆ—è¡¨
        """
        validated_clips = []

        for clip in clips:
            start_time = getattr(clip, 'start', 0)
            duration = getattr(clip, 'duration', 0)

            # æ£€æŸ¥ç‰‡æ®µæ˜¯å¦è¶…å‡ºæ—¶é•¿é™åˆ¶
            if start_time >= max_duration:
                print(f"   ç§»é™¤è¶…å‡ºæ—¶é•¿é™åˆ¶çš„ç‰‡æ®µ: start={start_time:.2f}s >= {max_duration:.2f}s")
                continue

            if start_time + duration > max_duration:
                # è£å‰ªç‰‡æ®µä»¥ç¬¦åˆæ—¶é•¿é™åˆ¶
                new_duration = max_duration - start_time
                if new_duration > 0.01:  # åªä¿ç•™æœ‰æ„ä¹‰çš„ç‰‡æ®µ
                    clip = clip.subclipped(0, new_duration)
                    print(f"   è£å‰ªç‰‡æ®µæ—¶é•¿: {duration:.2f}s -> {new_duration:.2f}s")
                    validated_clips.append(clip)
                else:
                    print(f"   ç§»é™¤è¿‡çŸ­çš„ç‰‡æ®µ: duration={new_duration:.2f}s")
            else:
                validated_clips.append(clip)

        return validated_clips

    # --- BEGIN PRIVATE HELPER METHODS ---
    def _create_video_background(
        self,
        duration: float,
        background_image_path: Optional[str] = None
    ) -> ImageClip:
        """(Helper) åˆ›å»ºè§†é¢‘èƒŒæ™¯ç‰‡æ®µï¼ˆå›¾ç‰‡æˆ–çº¯é»‘ï¼‰ã€‚"""
        if background_image_path and os.path.exists(background_image_path):
            bg_array = self.load_background_image(background_image_path)
            if bg_array is not None:
                print(f"   ä½¿ç”¨èƒŒæ™¯å›¾ç‰‡: {background_image_path}")
                return ImageClip(bg_array, duration=duration)
            else:
                print("   èƒŒæ™¯å›¾ç‰‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨çº¯é»‘èƒŒæ™¯æ›¿ä»£ã€‚")
                return ColorClip(size=(self.width, self.height), color=(0,0,0), duration=duration)
        else:
            if background_image_path:
                print(f"   èƒŒæ™¯å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨: {background_image_path}ã€‚ä½¿ç”¨çº¯é»‘èƒŒæ™¯ã€‚")
            else:
                print("   æœªä½¿ç”¨èƒŒæ™¯å›¾ç‰‡ï¼Œä½¿ç”¨çº¯é»‘èƒŒæ™¯ã€‚")
            return ColorClip(size=(self.width, self.height), color=(0,0,0), duration=duration)



    def _finalize_and_export_video(
        self,
        all_clips: List[ImageClip],
        audio_clip: AudioFileClip,
        output_path: str,
        temp_audio_file_suffix: str = "generic",
        ffmpeg_params_custom: Optional[List[str]] = None,
        draft_mode: bool = False
    ):
        """(Helper) åˆæˆæ‰€æœ‰ç‰‡æ®µå¹¶å¯¼å‡ºè§†é¢‘ã€‚

        Args:
            all_clips: æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
            audio_clip: éŸ³é¢‘ç‰‡æ®µ
            output_path: è¾“å‡ºè·¯å¾„
            temp_audio_file_suffix: ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶åç¼€
            ffmpeg_params_custom: è‡ªå®šä¹‰FFmpegå‚æ•°
            draft_mode: è‰ç¨¿æ¨¡å¼ï¼Œä½¿ç”¨å¿«é€Ÿç¼–ç è®¾ç½®
        """
        print("åˆæˆè§†é¢‘...")
        final_video = CompositeVideoClip(all_clips)
        final_video = final_video.with_audio(audio_clip)
        final_video = final_video.with_fps(self.fps)

        temp_audio_filename = f'temp-audio-{temp_audio_file_suffix}-{hash(output_path) % 10000}.m4a'

        # æ ¹æ®æ¨¡å¼é€‰æ‹©ç¼–ç é…ç½®
        if draft_mode:
            print("   ğŸš€ ä½¿ç”¨è‰ç¨¿è´¨é‡é…ç½®è¿›è¡Œå¿«é€Ÿç¼–ç ...")
            codec_to_use = 'h264_nvenc'  # ä¼˜å…ˆä½¿ç”¨NVENCç¡¬ä»¶ç¼–ç 
            preset_to_use = 'fast'
            actual_ffmpeg_params = ffmpeg_params_custom if ffmpeg_params_custom is not None else ['-cq', '28']
        else:
            print("   ğŸ¬ ä½¿ç”¨äº§å“è´¨é‡é…ç½®è¿›è¡Œç¼–ç ...")
            codec_to_use = 'libx264rgb'
            preset_to_use = 'medium'
            actual_ffmpeg_params = ffmpeg_params_custom if ffmpeg_params_custom is not None else ['-crf', '18']

        print(f"å¯¼å‡ºè§†é¢‘åˆ°: {output_path}")
        print(f"   ç¼–ç å™¨: {codec_to_use}, é¢„è®¾: {preset_to_use}, å‚æ•°: {actual_ffmpeg_params}")

        # å¼€å§‹è®¡æ—¶
        export_start_time = time.perf_counter()

        try:
            final_video.write_videofile(
                output_path,
                codec=codec_to_use,
                audio_codec='aac',
                temp_audiofile=temp_audio_filename,
                remove_temp=True,
                # verbose=False,
                logger=None,
                preset=preset_to_use,
                ffmpeg_params=actual_ffmpeg_params
            )
        except Exception as e:
            # è‰ç¨¿æ¨¡å¼ä¸‹NVENCå¤±è´¥æ—¶å¿«é€Ÿå›é€€åˆ°è½¯ä»¶ç¼–ç 
            if draft_mode and codec_to_use == "h264_nvenc":
                print(f"âš ï¸  NVENCç¼–ç å¤±è´¥ ({e})ï¼Œå›é€€åˆ°è½¯ä»¶ç¼–ç ...")
                final_video.write_videofile(
                    output_path,
                    codec='libx264rgb',
                    audio_codec='aac',
                    temp_audiofile=temp_audio_filename,
                    remove_temp=True,
                    # verbose=False,
                    logger=None,
                    preset='ultrafast',
                    ffmpeg_params=['-crf', '28']
                )
            else:
                raise
        finally:
            # ç»“æŸè®¡æ—¶å¹¶æ˜¾ç¤ºç»“æœ
            export_end_time = time.perf_counter()
            export_duration = export_end_time - export_start_time
            mode_desc = "è‰ç¨¿æ¨¡å¼" if draft_mode else "äº§å“æ¨¡å¼"
            print(f"âœ… è§†é¢‘å¯¼å‡ºå®Œæˆ ({mode_desc}): {export_duration:.2f} ç§’")
    # --- END PRIVATE HELPER METHODS ---


    def generate_bilingual_video(self,
                               main_timeline: 'LyricTimeline',
                               aux_timeline: Optional['LyricTimeline'] = None,
                               audio_path: str = "",
                               output_path: str = "",
                               background_image: Optional[str] = None,
                               t_max_sec: float = float('inf'),
                               draft_mode: bool = False) -> bool:
        """ç”ŸæˆåŒè¯­ç‰ˆæœ¬è§†é¢‘æˆ–å¢å¼ºç‰ˆè§†é¢‘ (çº¯OOPç‰ˆ)

        Args:
            main_timeline: ä¸»æ­Œè¯æ—¶é—´è½´
            aux_timeline: å‰¯æ­Œè¯æ—¶é—´è½´ï¼ˆå¯é€‰ï¼Œç”¨äºåŒè¯­æ¨¡å¼ï¼‰
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            background_image: èƒŒæ™¯å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            t_max_sec: æœ€å¤§æ—¶é•¿é™åˆ¶
            draft_mode: è‰ç¨¿æ¨¡å¼ï¼Œä½¿ç”¨å¿«é€Ÿç¼–ç è®¾ç½®ï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰

        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        """ä½¿ç”¨LyricTimelineå¯¹è±¡ç”Ÿæˆè§†é¢‘çš„æ ¸å¿ƒæ–¹æ³•"""

        # ç¡®å®šç”Ÿæˆæ¨¡å¼
        is_bilingual_mode = aux_timeline is not None
        mode_name = "åŒè¯­ç‰ˆ" if is_bilingual_mode else "å¢å¼ºç‰ˆ"

        try:
            print(f"å¼€å§‹ç”Ÿæˆ{mode_name}: {output_path}")

            # éŸ³é¢‘å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            print("åŠ è½½éŸ³é¢‘...")
            audio = AudioFileClip(audio_path)
            original_duration = audio.duration
            duration = min(original_duration, t_max_sec)

            if t_max_sec < original_duration:
                audio = audio.subclipped(0, t_max_sec)
                print(f"   éŸ³é¢‘å·²è£å‰ª: {original_duration:.1f}s -> {duration:.1f}s")
            else:
                print(f"   éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’")

            # æ˜¾ç¤ºæ—¶é—´è½´ä¿¡æ¯
            print(f"ä¸»æ—¶é—´è½´ä¿¡æ¯: {main_timeline.get_info()}")
            if aux_timeline:
                print(f"å‰¯æ—¶é—´è½´ä¿¡æ¯: {aux_timeline.get_info()}")

            # å¸ƒå±€è®¡ç®—å’Œå†²çªæ£€æµ‹ - ç»Ÿä¸€ä½¿ç”¨å¸ƒå±€å¼•æ“
            print("ä½¿ç”¨å¸ƒå±€å¼•æ“è¿›è¡Œè‡ªåŠ¨å¸ƒå±€...")

            # åˆ›å»ºå¸ƒå±€å¼•æ“ä½œä¸ºé»˜è®¤çš„timelineå®¹å™¨
            layout_engine = LayoutEngine(VerticalStackStrategy(spacing=30))

            # æ·»åŠ æ‰€æœ‰æ—¶é—´è½´å…ƒç´ 
            layout_engine.add_element(main_timeline)
            if aux_timeline:
                layout_engine.add_element(aux_timeline)

            # æ£€æµ‹å†²çª
            conflicts = layout_engine.detect_conflicts(self.width, self.height)
            if conflicts:
                print("æ£€æµ‹åˆ°å¸ƒå±€å†²çª:")
                for conflict in conflicts:
                    print(f"  - {conflict}")

                # è®¡ç®—è‡ªåŠ¨å¸ƒå±€
                layout_result = layout_engine.calculate_layout(self.width, self.height)
                print("åº”ç”¨è‡ªåŠ¨å¸ƒå±€è§£å†³æ–¹æ¡ˆ:")

                # åº”ç”¨å¸ƒå±€ç»“æœåˆ°æ—¶é—´è½´
                for element_id, rect in layout_result.element_positions.items():
                    print(f"  - {element_id}: {rect}")

                    # æ ¹æ®element_idæ‰¾åˆ°å¯¹åº”çš„timelineå¹¶æ›´æ–°å…¶ç­–ç•¥
                    if element_id == main_timeline.element_id:
                        self._apply_layout_to_timeline(main_timeline, rect)
                    elif aux_timeline and element_id == aux_timeline.element_id:
                        self._apply_layout_to_timeline(aux_timeline, rect)
            else:
                print("âœ… æ— å¸ƒå±€å†²çªï¼Œä½¿ç”¨åŸå§‹å¸ƒå±€")

            # æ˜¾ç¤ºæ‰€æœ‰æ—¶é—´è½´çš„å¸ƒå±€ä¿¡æ¯
            layout_result = layout_engine.calculate_layout(self.width, self.height)
            for element_id, rect in layout_result.element_positions.items():
                print(f"æ—¶é—´è½´ {element_id} å¸ƒå±€åŒºåŸŸ: {rect}")

            # èƒŒæ™¯å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            print("åˆ›å»ºèƒŒæ™¯...")
            background_clip = self._create_video_background(duration, background_image)

            # ä½¿ç”¨æ–°çš„LyricClipç»Ÿä¸€æ¸²æŸ“ç®¡é“
            print("åˆ›å»ºLyricClipç»Ÿä¸€æ¸²æŸ“å®¹å™¨...")

            # æ”¶é›†æ‰€æœ‰æ—¶é—´è½´
            timelines = []
            for element in layout_engine.elements:
                timelines.append(element)

            # åˆ›å»ºLyricClipï¼ˆæ–°æ–¹å¼ï¼‰
            lyric_clip = self.create_lyric_clip(timelines, duration)
            print(f"   âœ… LyricClipåˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(timelines)} ä¸ªæ—¶é—´è½´")

            # ä½¿ç”¨LyricClipè¿›è¡Œè§†é¢‘åˆæˆï¼ˆæ–°æ–¹å¼ï¼‰
            self._generate_video_with_lyric_clip(
                lyric_clip=lyric_clip,
                background_clip=background_clip,
                audio_clip=audio,
                output_path=output_path,
                draft_mode=draft_mode
            )

            print(f"{mode_name}è§†é¢‘ç”ŸæˆæˆåŠŸï¼")
            return True

        except Exception as e:
            print(f"{mode_name}ç”Ÿæˆå¤±è´¥: {e}")
            traceback.print_exc()
            return False

def demo_enhanced_features(config_path: Path, t_max_sec: float = float('inf'), draft_mode: bool = False):
    """ä½¿ç”¨é…ç½®æ–‡ä»¶ç”Ÿæˆæ­Œè¯è§†é¢‘ (çº¯OOPç‰ˆ)

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        t_max_sec: æœ€å¤§æ—¶é•¿é™åˆ¶
        draft_mode: è‰ç¨¿æ¨¡å¼ï¼Œä½¿ç”¨å¿«é€Ÿç¼–ç è®¾ç½®ï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰
    """
    print("ç²¾æ­¦è‹±é›„æ­Œè¯è§†é¢‘ç”Ÿæˆå™¨ - çº¯OOPç‰ˆ")
    print("=" * 50)

    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        print(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        config = load_lrc_mv_config(str(config_path))
        print("é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        print(f"   éŸ³é¢‘æ–‡ä»¶: {config.audio}")
        print(f"   ä¸»æ­Œè¯: {config.main_lrc.path} ({config.main_lrc.lang})")
        if config.aux_lrc:
            print(f"   å‰¯æ­Œè¯: {config.aux_lrc.path} ({config.aux_lrc.lang})")
        print(f"   èƒŒæ™¯å›¾ç‰‡: {config.background}")
        print(f"   è¾“å‡ºå°ºå¯¸: {config.width}x{config.height}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {config.output}")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        print("\néªŒè¯æ–‡ä»¶å­˜åœ¨æ€§...")
        config.validate_files()
        print("æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨")

    except Exception as e:
        print(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False

    # åˆ›å»ºç”Ÿæˆå™¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å°ºå¯¸
    generator = EnhancedJingwuGenerator(width=config.width, height=config.height, fps=DEFAULT_FPS)
    generator.default_font_size = 60
    print("\nå¼€å§‹ç”Ÿæˆè§†é¢‘...")

    # è·å–è·¯å¾„
    audio_path = config.get_audio_path()
    background_path = config.get_background_path()
    output_path = config.get_output_path()

    # ä½¿ç”¨LyricTimeline OOPæ¥å£
    print("ä½¿ç”¨LyricTimeline OOPæ¥å£")

    # åˆ›å»ºä¸»æ—¶é—´è½´ - æ€»æ˜¯ä½¿ç”¨å¢å¼ºé¢„è§ˆæ¨¡å¼
    main_lrc_path = config.get_main_lrc_path()

    # ä»é…ç½®ä¸­è·å–å­—ä½“å¤§å°ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
    main_font_size = config.main_lrc.font_size or 80
    print(f"ä¸»æ­Œè¯å­—ä½“å¤§å°: {main_font_size}")
    from layout_types import LyricStyle
    main_style = LyricStyle(
        font_size=main_font_size,
        highlight_color='#FFD700',
        glow_enabled=True
    )

    main_timeline = LyricTimeline.from_lrc_file(
        str(main_lrc_path),
        language="chinese",
        display_mode=LyricDisplayMode.ENHANCED_PREVIEW,
        style=main_style
    )

    aux_timeline = None
    if config.aux_lrc:
        # åˆ›å»ºå‰¯æ—¶é—´è½´ - ä½¿ç”¨ç®€å•æ¨¡å¼ï¼Œæ˜¾ç¤ºåœ¨ä¸‹æ–¹
        aux_lrc_path = config.get_aux_lrc_path()

        # ä»é…ç½®ä¸­è·å–å‰¯æ­Œè¯å­—ä½“å¤§å°ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
        aux_font_size = config.aux_lrc.font_size or 60
        print(f"å‰¯æ­Œè¯å­—ä½“å¤§å°: {aux_font_size}")
        aux_style = LyricStyle(
            font_size=aux_font_size,
            font_color='white',
            highlight_color='#FFD700'
        )

        aux_timeline = LyricTimeline.from_lrc_file(
            str(aux_lrc_path),
            language="english",
            display_mode=LyricDisplayMode.SIMPLE_FADE,
            style=aux_style
        )
        # è®¾ç½®å‰¯æ­Œè¯æ˜¾ç¤ºä½ç½®ï¼Œé¿å…ä¸ä¸»æ­Œè¯é‡å 
        aux_timeline.set_display_mode(
            LyricDisplayMode.SIMPLE_FADE,
            y_position=config.height // 2 + 200,  # æ˜¾ç¤ºåœ¨æ›´ä¸‹æ–¹ï¼Œé¿å…é‡å 
            is_highlighted=False
        )

    # æ˜¾ç¤ºæ—¶é—´è½´ä¿¡æ¯
    print(f"ä¸»æ—¶é—´è½´ä¿¡æ¯: {main_timeline.get_info()}")
    if aux_timeline:
        print(f"å‰¯æ—¶é—´è½´ä¿¡æ¯: {aux_timeline.get_info()}")

    # è®¡ç®—å¸ƒå±€ä¿¡æ¯
    main_rect = main_timeline.calculate_required_rect(config.width, config.height)
    print(f"ä¸»æ—¶é—´è½´æ‰€éœ€åŒºåŸŸ: {main_rect}")

    if aux_timeline:
        aux_rect = aux_timeline.calculate_required_rect(config.width, config.height)
        print(f"å‰¯æ—¶é—´è½´æ‰€éœ€åŒºåŸŸ: {aux_rect}")

        if main_rect.overlaps_with(aux_rect):
            print("è­¦å‘Š: æ—¶é—´è½´æ˜¾ç¤ºåŒºåŸŸé‡å ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å¸ƒå±€")

    # ç”Ÿæˆè§†é¢‘
    success = generator.generate_bilingual_video(
        main_timeline=main_timeline,
        aux_timeline=aux_timeline,
        audio_path=str(audio_path),
        output_path=str(output_path),
        background_image=str(background_path),
        t_max_sec=t_max_sec,
        draft_mode=draft_mode
    )

    if success:
        print("\nè§†é¢‘ç”ŸæˆæˆåŠŸï¼")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
        if output_path.exists():
            file_size = output_path.stat().st_size / (1024 * 1024)  # MB
            print(f"æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
    else:
        print("\nè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼")

    return success

def demo_draft_mode(config_path: Path, t_max_sec: float = float('inf')):
    """è‰ç¨¿æ¨¡å¼æ¼”ç¤º - å¿«é€Ÿç”Ÿæˆç”¨äºå¼€å‘æµ‹è¯•"""
    print("ğŸš€ è‰ç¨¿æ¨¡å¼æ¼”ç¤º - å¿«é€Ÿç¼–ç ")
    print("=" * 50)
    print("æ³¨æ„: è‰ç¨¿æ¨¡å¼ä½¿ç”¨å¿«é€Ÿç¼–ç è®¾ç½®ï¼Œè´¨é‡è¾ƒä½ä½†é€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆå¼€å‘æµ‹è¯•ä½¿ç”¨")
    print()

    return demo_enhanced_features(config_path, t_max_sec, draft_mode=True)

if __name__ == "__main__":
    # é»˜è®¤ä½¿ç”¨è‰ç¨¿æ¨¡å¼è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    # demo_draft_mode(Path(r"ç²¾æ­¦è‹±é›„\lrc-mv.yaml"), t_max_sec=20.0)

    # å¦‚éœ€äº§å“è´¨é‡ï¼Œå–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œ
    demo_enhanced_features(Path(r"ç²¾æ­¦è‹±é›„\lrc-mv.yaml"))
